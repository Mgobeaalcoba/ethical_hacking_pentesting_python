import requests
import argparse
import socket
import json
import pandas as pd
from os import path
from bs4 import BeautifulSoup

parser = argparse.ArgumentParser(description="Detector de Cabeceras o Headers")
parser.add_argument('-t', '--target', help="Objetivo") # Le agrego opciones a mi programa por consola. target será la variable que contenga mi objetivo
parser = parser.parse_args()

def get_domains(fuente='https://es.semrush.com/trending-websites/ar/all'):
    agent = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"
    }
    cookies = {
        'GCLB': 'CIXXrbDxlebSYhAD',
        'GCLB': 'CL3S863X28yQnwEQAw',
        'PHPSESSID': '52a703e3dc0d5f3623cd3d934dd7e551',
        'SSO-JWT': 'eyJhbGciOiJFUzI1NiIsInR5cCI6IkpXVCJ9.eyJqdGkiOiI1MmE3MDNlM2RjMGQ1ZjM2MjNjZDNkOTM0ZGQ3ZTU1MSIsImlhdCI6MTcxOTMzNDExOSwiaXNzIjoic3NvIn0.ZWQwNtDvXl-RpDILiXjAacxRw5n7Qn1WDUybXLad6JySxbd3EH-oOjUyyCNet5HKTAsfcsdah8vXlty01shrAg',
        'visit_first': '1719334125135',
        'ga_exp_c41234be21bd4796bbf8e763': '0',
        'intercom-id-cs07vi2k': '49ee0d0e-593d-4fbb-a1cd-cc713c879476',
        'intercom-session-cs07vi2k': '',
        'intercom-device-id-cs07vi2k': '62a9ff79-30a0-4681-aa8e-870924ae862b'
    }
    request = requests.get(fuente, headers=agent, cookies=cookies)
    soup = BeautifulSoup(request.text, 'html5lib')
    print(type(soup))
    soup_a = soup.find_all('a', class_='___SBoxInline_1tphm_gg_ NZFMZoXJrDaOPTLvk6JZ')
    domain_list = []
    for a in soup_a:
        domain_list.append(f'www.{a.text}')
    print("Lista de 20 sitios más visitados de Argentina construida!!!")
    return domain_list


def main():
    """
    1. Pasar por parametro "-t" el dominio que se desea consultar o en su defecto cargar la serie a consultar acá.
    """
    if parser.target is not None:
        targets = parser.target
        targets = targets.split(',')
        print(targets)
        print(type(targets))
    else:
        targets = get_domains()

    for target in targets:
        ip = socket.gethostbyname(target)
        
        name_file = target.split('.')[1]
        
        sitio = f'https://ipinfo.io/{ip}/json'
        agent = {
            "User-Agent": "Firefox"
        }

        request = requests.get(sitio, headers=agent)
        print(request.text)

        with open(f'exportables/{name_file}.json', 'w') as json_file:
            json_file.write(request.text)
            print("Archivo Json guardado con éxito!!!")

        request_json = json.loads(request.text)
        request_json["domain"] = f'{target}'

        print()
        print(json.dumps(request_json, indent=4))
        print()

        request_list = [request_json]

        df = pd.DataFrame(request_list)
        print(df.info())

        if path.exists('exportables/ipinfo_dataset.xlsx'):
            file = 'exportables/ipinfo_dataset.xlsx'
            df_new = pd.read_excel(file)
            df_concat = pd.concat([df, df_new], ignore_index=True)
            df_concat = df_concat.drop_duplicates(keep='last')
            df_concat.to_excel('exportables/ipinfo_dataset.xlsx', index=False)
            print("Nuevos datos cargados en 'exportables/ipinfo_dataset.xlsx'")
        else:
            df.to_excel('exportables/ipinfo_dataset.xlsx', index=False)
            print("Archivo creado con éxito dentro de la carpeta 'exportables'...")
     
if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        print("Saliendo...")
        exit()